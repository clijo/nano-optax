# basic optimizers in JAX 

~~A library~~ an excuse for me to learn JAX by writing a few optimization algorithms. 

## TODO 

Algorithms:
- [x] Gradient Descent
- [ ] SGD
- [ ] Proximal Gradient Descent
- [ ] Accelerated Gradient Descent (a la Nesterov)
- [ ] SAGA, SVRG (variance reduction)
- [ ] Coordinate Descent
- [ ] Conjugate Gradient
- [ ] Newton's Method
- [ ] Quasi-Newton (BFGS, L-BFGS)